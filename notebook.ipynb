{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Activity Recognition Using Smartphones\n",
    "\n",
    "#### Classification Model Comparison\n",
    "\n",
    "#### Name: Akeem Jokosenumi\n",
    "\n",
    "#### Student ID: G00366442\n",
    "\n",
    "#### Introduction\n",
    "\n",
    "#### The Human Activity Recognition (HAR) dataset is used in this notebook to examine three classification algorithms: Random Forest, Logistic Regression, and Support Vector Machine (SVM). The main objective is to identify the optimal model for deployment by analysing a number of assessment parameters, including training duration, accuracy, and macro F1 score.\n",
    "\n",
    "#### The HAR dataset includes both time domain and frequency domain characteristics from a variety of sensor signals captured from cellphones. We examine the dataset, conduct feature analysis, preprocess the data, create classification models, and then evaluate the results in the ensuing sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "import warnings\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.utils import resample\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Set plotting style (using seaborn theme)\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set student ID as random seed so G00366442 becomes 366442\n",
    "import numpy as np\n",
    "\n",
    "STUDENT_ID = 366442\n",
    "np.random.seed(STUDENT_ID)\n",
    "\n",
    "# Configure common parameters\n",
    "FIGURES_SIZE = (12, 8)\n",
    "CV_FOLDS = 5  # Number of cross-validation folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify imports are working\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Matplotlib version: {matplotlib.__version__}\")\n",
    "print(f\"Seaborn version: {sns.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Overview and Feature Analysis\n",
    "\n",
    "In this section, we:\n",
    "- Load the HAR dataset's feature names and activity labels.\n",
    "- Convert numerical activity labels into activity names that are readable by humans.\n",
    "- Examine the feature distribution, taking into account the frequency and temporal domain feature counts.\n",
    "- Examine basic feature data and visualise the distribution of activity.\n",
    "\n",
    "The study sheds light on the data's structure, which is essential before using any machine learning techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Load the UCI HAR dataset.\n",
    "    - 'dataset.txt' contains the features.\n",
    "    - 'targets.txt' contains the labels.\n",
    "    - 'features.txt' contains feature names.\n",
    "    \"\"\"\n",
    "    # Load feature names and strip extra spaces\n",
    "    features = pd.read_csv('UCI HAR/features.txt', sep='\\s+', header=None, dtype=str)\n",
    "    feature_names = features[1].str.strip().tolist()\n",
    "    \n",
    "    # Load feature data and assign feature names (as float)\n",
    "    X = pd.read_csv('UCI HAR/dataset.txt', sep='\\s+', header=None, dtype=float)\n",
    "    X.columns = feature_names\n",
    "    \n",
    "    # Check for duplicate column names and resolve them\n",
    "    X.columns = [f'{col}_{i}' if X.columns.tolist().count(col) > 1 else col for i, col in enumerate(X.columns)]\n",
    "    \n",
    "    # Load target labels as a DataFrame with column name 'activity'\n",
    "    y = pd.read_csv('UCI HAR/targets.txt', sep='\\s+', header=None, names=['activity'])\n",
    "    \n",
    "    # Ensure activity column is numeric\n",
    "    y['activity'] = pd.to_numeric(y['activity'], errors='coerce')\n",
    "    y = y.dropna(subset=['activity'])\n",
    "    y['activity'] = y['activity'].astype(int)\n",
    "    \n",
    "    # Define activity label mapping\n",
    "    activity_labels = {\n",
    "        1: 'Walking',\n",
    "        2: 'Walking Upstairs',\n",
    "        3: 'Walking Downstairs',\n",
    "        4: 'Sitting',\n",
    "        5: 'Standing',\n",
    "        6: 'Laying'\n",
    "    }\n",
    "    \n",
    "    # Map numeric labels to activity names for visualization\n",
    "    y['activity_name'] = y['activity'].map(activity_labels)\n",
    "    \n",
    "    return X, y, activity_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Class Imbalance with Random Oversampling\n",
    "\n",
    "#### **Purpose:**\n",
    "In real-world datasets, the model may favour majority classes due to **imbalanced learning**, where some classes may have much less samples than others. In order to solve this, we create more synthetic samples for under-represented classes using **Random Oversampling**.\n",
    "\n",
    "#### **How It Works:**\n",
    "1. `RandomOverSampler` is used to apply **Random Oversampling (ROS)** to the dataset, guaranteeing that each activity class has an equal amount of samples.\n",
    "2. **Labels for Activities Are Maintained**: The function makes sure that the labels and the names of the corresponding activities are consistently mapped.\n",
    "3. **Maintains Data Integrity**: To maintain feature names and column consistency, the resampled dataset is converted back into a structured DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_classes(X, y):\n",
    "    \"\"\"I'll use random oversampling to balance the distribution of the classes.\"\"\"\n",
    "    ros = RandomOverSampler(random_state=366442)\n",
    "    \n",
    "    # Ensure y is using integer labels\n",
    "    y_int = y.copy()\n",
    "    y_int['activity'] = y_int['activity'].astype(int)\n",
    "    \n",
    "    X_resampled, y_resampled = ros.fit_resample(X, y_int['activity'])\n",
    "    \n",
    "    # Convert back to pandas objects (preserve column names)\n",
    "    X_resampled = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "    y_resampled = pd.DataFrame({'activity': y_resampled})\n",
    "    y_resampled['activity'] = y_resampled['activity'].astype(int)\n",
    "    \n",
    "    # Map activity names\n",
    "    activity_labels = {\n",
    "        1: 'Walking',\n",
    "        2: 'Walking Upstairs',\n",
    "        3: 'Walking Downstairs',\n",
    "        4: 'Sitting',\n",
    "        5: 'Standing',\n",
    "        6: 'Laying'\n",
    "    }\n",
    "    y_resampled['activity_name'] = y_resampled['activity'].map(activity_labels)\n",
    "    \n",
    "    return X_resampled, y_resampled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Transformation\n",
    "- **Feature Standardization**: Using `StandardScaler` to normalize features to zero mean and unit variance\n",
    "- **Missing Value Treatment**: Rows with NaN values are removed\n",
    "- **Outlier Removal**: Data points beyond 3 standard deviations are filtered out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(X):\n",
    "    \"\"\"\n",
    "    I will remove rows with NaN values and extreme outliers..\n",
    "    Return the cleaned data along with a boolean mask that indicates which rows were kept.\n",
    "    \"\"\"\n",
    "    X_clean = X.copy()\n",
    "    mask = pd.Series(True, index=X.index)\n",
    "    \n",
    "    # Remove rows with any NaN values\n",
    "    mask = mask & ~X_clean.isna().any(axis=1)\n",
    "    \n",
    "    # Remove extreme outliers (values beyond 3 standard deviations)\n",
    "    for col in X_clean.columns:\n",
    "        mean = X_clean[col].mean()\n",
    "        std = X_clean[col].std()\n",
    "        outlier_mask = (X_clean[col] - mean).abs() <= 3 * std\n",
    "        mask = mask & outlier_mask\n",
    "    \n",
    "    return X_clean[mask], mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Class Distribution and Model Performance\n",
    "\n",
    "#### **Class Distribution Plot**\n",
    "- To **visualise the distribution of activity classes** in the dataset, utilise the `plot_class_distribution()` method.\n",
    "- **Steps:**\n",
    "  - The activity labels are converted into integers to ensure proper sorting.\n",
    "  - The count of samples for each activity class is calculated.\n",
    "  - With the x-axis representing the activity classes and the y-axis displaying the sample count for each class, seaborn creates a **bar chart**.\n",
    "- **Purpose:** This visualisation helps to **identify any class imbalances** in the dataset, as over- or under-representation of certain classes may affect the model's performance. Prior to model training, relevant changes (such weighting or resampling) can be made thanks to early detection of these imbalances.\n",
    "\n",
    "#### **Confusion Matrix Visualization**\n",
    "- The function `plot_confusion_matrix()` **evaluates the model’s performance** by comparing the true labels (`y_true`) with the predicted labels (`y_pred`).\n",
    "- **Steps:**\n",
    "  - The true and predicted labels are both converted to integer types for consistency.\n",
    "  - A confusion matrix is computed, showing how many instances of each activity were correctly classified (diagonal) and misclassified (off-diagonal).\n",
    "  - The confusion matrix is displayed as a **heatmap** using `ConfusionMatrixDisplay` for clear visualization, where the intensity of the color indicates the number of instances in each category.\n",
    "- **Purpose:** This visualization highlights where the model is making **misclassifications**, helping to identify specific activities that are often confused with others. Understanding these errors can guide further improvements to the model, such as tuning the algorithm or adjusting the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_distribution(y, title, activity_labels):\n",
    "    \"\"\"Visualize the class distribution\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Ensure 'activity' is integer type\n",
    "    y_plot = y.copy()\n",
    "    y_plot['activity'] = y_plot['activity'].astype(int)\n",
    "    \n",
    "    counts = y_plot['activity'].value_counts()\n",
    "    counts.index = counts.index.astype(int)\n",
    "    counts = counts.sort_index()\n",
    "    \n",
    "    x_labels = [activity_labels.get(idx, f'Unknown-{idx}') for idx in counts.index]\n",
    "    \n",
    "    sns.barplot(x=x_labels, y=counts.values)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Activity\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name, activity_labels):\n",
    "    \"\"\"Visualize model performance via confusion matrix.\"\"\"\n",
    "    y_true = y_true.astype(int)\n",
    "    y_pred = np.array(y_pred, dtype=int)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(activity_labels.values()))\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    disp.plot(ax=ax, cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Model Training and Evaluation**  \n",
    "   - The **three classifiers** that are trained are Random Forest, SVM, and Logistic Regression.  \n",
    "   - Evaluates each model based on **accuracy, precision, recall, and F1-score**.  \n",
    "   - **Visualizes confusion matrices** to analyze misclassification patterns.\n",
    "\n",
    " **Model Comparison and Selection**  \n",
    "   - Evaluates models for accuracy and performance criteria using a **bar chart**.\n",
    "   - Chooses the **most effective model** according to accuracy.  \n",
    "   - Key contributing elements are highlighted by visualising feature relevance if **Random Forest is the best**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(366442)\n",
    "    \n",
    "    print(\"Loading data...\")\n",
    "    X, y, activity_labels = load_data()\n",
    "    \n",
    "    print(f\"Total number of features: {len(X.columns)}\")\n",
    "    print(\"\\nFirst few features:\")\n",
    "    display(pd.DataFrame(X.columns[:10], columns=['Feature']))\n",
    "    \n",
    "    print(\"\\nFeature name statistics:\")\n",
    "    print(f\"Unique features: {len(set(X.columns))}\")\n",
    "    print(f\"Features beginning with 't': {sum(col.startswith('t') for col in X.columns)}\")\n",
    "    print(f\"Features beginning with 'f': {sum(col.startswith('f') for col in X.columns)}\")\n",
    "    \n",
    "    print(\"\\nActivity data type:\", y['activity'].dtype)\n",
    "    print(\"Activity first few values:\")\n",
    "    print(y['activity'].head())\n",
    "    \n",
    "    plot_class_distribution(y, \"Overall Activity Distribution\", activity_labels)\n",
    "    \n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=366442, stratify=y['activity'])\n",
    "    \n",
    "    print(\"Balancing training data...\")\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "    X_train_balanced, y_train_balanced = balance_classes(X_train, y_train)\n",
    "    \n",
    "    plot_class_distribution(y_train_balanced, \"Training Data Distribution (Balanced)\", activity_labels)\n",
    "    plot_class_distribution(y_test, \"Test Data Distribution\", activity_labels)\n",
    "    \n",
    "    print(\"Cleaning data...\")\n",
    "    X_train_clean, train_mask = clean_data(X_train_balanced)\n",
    "    X_test_clean, test_mask = clean_data(X_test)\n",
    "    \n",
    "    # Filter corresponding labels using the boolean mask\n",
    "    y_train_clean = y_train_balanced.loc[train_mask].reset_index(drop=True)\n",
    "    y_train_clean['activity'] = y_train_clean['activity'].astype(int)\n",
    "    y_test_clean = y_test.loc[test_mask].reset_index(drop=True)\n",
    "    y_test_clean['activity'] = y_test_clean['activity'].astype(int)\n",
    "    \n",
    "    print(\"Standardizing data...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_clean), columns=X_train_clean.columns)\n",
    "    X_test_scaled = pd.DataFrame(scaler.transform(X_test_clean), columns=X_test_clean.columns)\n",
    "    \n",
    "    # Define classifiers for evaluation\n",
    "    models = {\n",
    "        'Random Forest': RandomForestClassifier(random_state=366442),\n",
    "        'SVM': SVC(random_state=366442),\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=366442)\n",
    "    }\n",
    "    \n",
    "    print(\"Evaluating models...\")\n",
    "    summary_data = []\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n{'='*50}\\nEvaluating {name}\\n{'='*50}\")\n",
    "        y_train_int = y_train_clean['activity'].astype(int)\n",
    "        model.fit(X_train_scaled, y_train_int)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "        plot_confusion_matrix(y_test_clean['activity'], y_pred, name, activity_labels)\n",
    "        \n",
    "        print(\"\\nClassification Report:\")\n",
    "        report = classification_report(y_test_clean['activity'], y_pred, target_names=list(activity_labels.values()), digits=4, output_dict=True)\n",
    "        print(classification_report(y_test_clean['activity'], y_pred, target_names=list(activity_labels.values()), digits=4))\n",
    "        \n",
    "        summary_data.append({\n",
    "            'Model': name,\n",
    "            'Accuracy': report['accuracy'],\n",
    "            'Macro Precision': report['macro avg']['precision'],\n",
    "            'Macro Recall': report['macro avg']['recall'],\n",
    "            'Macro F1-score': report['macro avg']['f1-score']\n",
    "        })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data).set_index('Model')\n",
    "    print(\"\\nModel Performance Summary:\")\n",
    "    print(summary_df.to_string(float_format=lambda x: f\"{x:.4f}\"))\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    summary_df.plot(kind='bar', figsize=(12, 8))\n",
    "    plt.title('Model Performance Comparison')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    best_model_name = summary_df['Accuracy'].idxmax()\n",
    "    best_model = models[best_model_name]\n",
    "    print(\"\\nBest Model Selection:\")\n",
    "    print(f\"Selected Model: {best_model_name}\")\n",
    "    \n",
    "    if best_model_name == 'Random Forest' and hasattr(best_model, 'feature_importances_'):\n",
    "        y_train_int = y_train_clean['activity'].astype(int)\n",
    "        best_model.fit(X_train_scaled, y_train_int)\n",
    "        feature_imp = pd.DataFrame({\n",
    "            'feature': X_train_scaled.columns,\n",
    "            'importance': best_model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False).head(10)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(data=feature_imp, x='importance', y='feature')\n",
    "        plt.title('Top 10 Feature Importance (Random Forest)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Synthetic data is generated based on the number of features. The following preprocessing steps are performed:\n",
    "\n",
    "- **Scaling:** Features are scaled using `StandardScaler` to standardize the data.\n",
    "- **Dimensionality Reduction:** Principal Component Analysis (PCA) is applied to reduce dimensionality while retaining 95% of the variance.\n",
    "- **Train-Test Split:** The PCA-transformed data is split into training and test sets for model evaluation.\n",
    "\n",
    "These steps ensure that the data is in a suitable form for training and evaluating the classification models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Correlation Analysis (First 20 Features)\n",
    "X, y, activity_labels = load_data()\n",
    "\n",
    "# Select first 20 features and check for duplicates\n",
    "feature_subset = X.iloc[:, :20]\n",
    "\n",
    "# Verify unique feature names\n",
    "print(\"First 20 feature names:\")\n",
    "print(feature_subset.columns.tolist())\n",
    "\n",
    "# Look for any duplicate columns\n",
    "duplicate_cols = feature_subset.columns[feature_subset.columns.duplicated()]\n",
    "if not duplicate_cols.empty:\n",
    "    print(f\"\\nWarning: Duplicate features detected - {duplicate_cols.tolist()}\")\n",
    "    # Remove duplicate columns (keeps first occurrence)\n",
    "    feature_subset = feature_subset.loc[:, ~feature_subset.columns.duplicated()]\n",
    "    print(\"Removed duplicate columns\")\n",
    "\n",
    "# Use the cleaned data to recalculate the correlation matrix\n",
    "correlation_matrix = feature_subset.corr()\n",
    "\n",
    "# Create a correlation heatmap plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, cmap='coolwarm', center=0, square=True,\n",
    "            xticklabels=True, yticklabels=True)\n",
    "plt.title('Cleaned Correlation Matrix of First 20 Features (Real Data)')\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find and print feature pairs that are substantially connected (perfect correlations excluded)\n",
    "upper_triangle = np.triu(np.abs(correlation_matrix), k=1)\n",
    "high_corr = np.where((upper_triangle > 0.8) & (upper_triangle < 1.0))  # Don't include perfect correlations\n",
    "\n",
    "high_corr_pairs = [(correlation_matrix.index[i], \n",
    "                    correlation_matrix.columns[j],\n",
    "                    correlation_matrix.iloc[i, j])\n",
    "                   for i, j in zip(*high_corr)]\n",
    "\n",
    "print(\"\\nSignificant correlated feature pairs (0.8 < |correlation| < 1.0):\")\n",
    "for feat1, feat2, corr in high_corr_pairs[:10]:  # Show the first ten significant pairs\n",
    "    print(f\"{feat1} -- {feat2}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building and Evaluation\n",
    "\n",
    "We use the following strategies to construct three classification models:\n",
    "- **Support Vector Machine (SVM)**\n",
    "- **Logistic Regression**\n",
    "- **Random Forest**\n",
    "\n",
    "After each model has been trained on the preprocessed data, it is evaluated using cross-validation. Among the metrics used for evaluation are:\n",
    "- **Accuracy**\n",
    "- **Precision, Recall, and F1-Score** (as shown in the classification report)\n",
    "- **Confusion Matrix** to display the model's performance in several activity classes\n",
    "\n",
    "The advantages and disadvantages of each model are thoroughly evaluated in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GridSearchCV parameter grid\n",
    "param_grid = {\n",
    "    'classifier__C': [0.1, 1, 10],  # Parameter for regularisation\n",
    "    'classifier__gamma': ['scale', 'auto'],  # Kernel coefficient\n",
    "    'classifier__kernel': ['rbf', 'linear'],  # Kernel type\n",
    "    'pca__n_components': [0.90, 0.95, 0.99],  # PCA components\n",
    "}\n",
    "\n",
    "# Create the pipeline using imblearn Pipeline and include SVM, PCA, and SMOTE\n",
    "pipeline = ImbPipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(svd_solver='full')),\n",
    "    ('smote', SMOTE(random_state=366442)),\n",
    "    ('classifier', SVC())\n",
    "])\n",
    "\n",
    "# Run Grid Search while using five-fold cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "\n",
    "# Fit the training data (X_train, y_train) to the grid search.\n",
    "print(\"Fitting GridSearchCV...\")\n",
    "grid_search.fit(X_train, y_train['activity'])  # Utilise just the activity column\n",
    "\n",
    "# Use the grid search to find the optimal parameters\n",
    "print(\"\\nBest parameters found:\", grid_search.best_params_)\n",
    "\n",
    "# Use the grid search to choose the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Train the ideal model using the hyperparameters that have been optimised.\n",
    "print(\"\\nTraining best model...\")\n",
    "best_model.fit(X_train, y_train['activity'])\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Examine the functioning of the model\n",
    "print(\"\\nModel Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test['activity'], y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test['activity'], y_pred))\n",
    "\n",
    "# Utilise PCA on the scaled data that has already been processed by the pipeline\n",
    "pca = best_model.named_steps['pca']\n",
    "X_pca = pca.transform(X_train.to_numpy())\n",
    "\n",
    "# Described Variance Cumulative Variance and Ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_variance_ratio = explained_variance_ratio.cumsum()\n",
    "\n",
    "# Plot explained variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(explained_variance_ratio) + 1), cumulative_variance_ratio, marker='o', linestyle='-')\n",
    "plt.axhline(y=0.95, color='r', linestyle='--', label='95% Explained Variance')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "plt.title('PCA Explained Variance Ratio (Scaled Data)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Determine how many components are required for a 95% variance\n",
    "n_components_95 = int(np.argmax(cumulative_variance_ratio >= 0.95) + 1)\n",
    "print(f\"\\nNumber of components needed for 95% variance: {n_components_95}\")\n",
    "\n",
    "# Look at the traits that comprise the majority of the primary components.\n",
    "top_n_components = pca.components_[:n_components_95]\n",
    "\n",
    "# Create a DataFrame with the loadings for easy visualisation.\n",
    "feature_names = X_train.columns if hasattr(X_train, \"columns\") else [f'Feature {i}' for i in range(X_train.shape[1])]\n",
    "loadings_df = pd.DataFrame(\n",
    "    np.abs(top_n_components.T),  # Use absolute values to calculate the contribution\n",
    "    columns=[f'PC{i+1}' for i in range(n_components_95)], \n",
    "    index=feature_names\n",
    ")\n",
    "\n",
    "# The primary characteristics that contribute to each fundamental component\n",
    "for i in range(min(5, n_components_95)):  # Show top 5 components or less\n",
    "    print(f\"\\nTop 5 features contributing to Principal Component {i+1}:\")\n",
    "    top_contributors = loadings_df.nlargest(5, f'PC{i+1}')[[f'PC{i+1}']]\n",
    "    print(top_contributors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Comparison and Best Model Selection\n",
    "\n",
    "Following testing on a hold-out set and cross-validation evaluation of the models, we compare them according to:\n",
    "- **Accuracy**\n",
    "- **Macro Average F1 Score**\n",
    "- **Training Time**\n",
    "\n",
    "Bar plots are used to visualise the results, which are also summarised in an extensive table. The Random Forest model stands out as the top contender based on these several factors because of its improved accuracy and manageable training duration. Furthermore, Random Forest includes built-in benefits such feature importance rankings, managing high-dimensional data, and lowering the chance of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Cleaning Function\n",
    "def clean_data_with_mask(X, y):\n",
    "    \"\"\"Remove outliers using the Z-score method and maintain label alignment.\"\"\"\n",
    "    z_scores = np.abs((X - X.mean()) / X.std().replace(0, np.nan))\n",
    "    mask = (z_scores < 3).all(axis=1)\n",
    "    return X[mask], y[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to balance classes\n",
    "def balance_classes(X, y):\n",
    "    \"\"\"Balance the classes using SMOTE and return balanced features and labels.\"\"\"\n",
    "    # Ensure `y` is a Series\n",
    "    if isinstance(y, pd.DataFrame):\n",
    "        y = y.squeeze()  # If required, convert a dataframe to a series.\n",
    "    \n",
    "    # To resample, create a composite DataFrame\n",
    "    combined_data = X.copy()\n",
    "    combined_data['target'] = y\n",
    "    \n",
    "    # Minority classes should be upsampled to match the majority class\n",
    "    max_class_size = y.value_counts().max()\n",
    "    balanced_dfs = []\n",
    "    \n",
    "    for cls in y.unique():\n",
    "        class_data = combined_data[combined_data['target'] == cls]\n",
    "        resampled = resample(class_data, \n",
    "                           replace=True, \n",
    "                           n_samples=max_class_size, \n",
    "                           random_state=366442)\n",
    "        balanced_dfs.append(resampled)\n",
    "    \n",
    "    # Combine all balanced classes and shuffle the data\n",
    "    balanced_data = pd.concat(balanced_dfs)\n",
    "    balanced_data = balanced_data.sample(frac=1, random_state=366442)  # Shuffle data\n",
    "    \n",
    "    # Split back into features and target the balanced data\n",
    "    X_balanced = balanced_data.drop('target', axis=1)\n",
    "    y_balanced = balanced_data['target']\n",
    "    \n",
    "    return X_balanced, y_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose and Role of This Section\n",
    "\n",
    "The Human Activity Recognition (HAR) dataset must be **loaded, preprocessed, and machine learning models** must be trained in this section.\n",
    "\n",
    "- **Data Loading**: Reads the dataset, gives the features the proper names, and gets it ready for training.\n",
    "- **Train-Test Splitting**: Maintaining class balance, the dataset is split into **80% training** and **20% testing**.\n",
    "- **Feature Scaling**: Standardises feature values to avoid scale-related bias and enhance model performance.\n",
    "- **Handling Imbalanced Data**: Uses the Synthetic Minority Oversampling Technique (SMOTE) to balance the distribution of classes.\n",
    "- **Model Training & Evaluation**: Trains three models (**SVM, Random Forest, and Logistic Regression**), assesses how well each performs, and chooses the best model based on cross-validation and accuracy findings.\n",
    "\n",
    "The objective is to **train robust classification models, identify the best model for deployment, and efficiently prepare the dataset**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load dataset and features \n",
    "features_list = pd.read_csv(\"UCI HAR/features.txt\", delim_whitespace=True, header=None)\n",
    "features_list[1] = features_list[1].astype(str) + '_' + features_list.index.astype(str)\n",
    "dataset = pd.read_csv(\"UCI HAR/dataset.txt\", delim_whitespace=True, header=None)\n",
    "dataset.columns = features_list[1].values\n",
    "targets = pd.read_csv(\"UCI HAR/targets.txt\", header=None).values.ravel()\n",
    "\n",
    "# Divide the data into test and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, targets, test_size=0.2, random_state=42, stratify=targets)\n",
    "\n",
    "# Standardise the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Use SMOTE to balance classes\n",
    "smote = SMOTE(random_state=366442)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Define models for comparison\n",
    "models = {\n",
    "    'SVM': SVC(kernel='rbf', C=1.0, gamma='scale'),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=366442),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=500)\n",
    "}\n",
    "\n",
    "# Dictionary to document training times and cross-validation results\n",
    "training_times = {}\n",
    "cv_results = {}\n",
    "\n",
    "# Data structure for storing information about model comparisons\n",
    "comparison_data = []\n",
    "\n",
    "# For training, assessment, and cross-validation, iterate through every model\n",
    "for name, model in models.items():\n",
    "    # Cross-validation for model performance evaluation\n",
    "    scores = cross_val_score(model, X_train_balanced, y_train_balanced, cv=5, scoring='accuracy')\n",
    "    cv_results[name] = {\n",
    "        'mean': scores.mean(),\n",
    "        'std': scores.std()\n",
    "    }\n",
    "\n",
    "    # Measure training time and train the model\n",
    "    start_time = time()\n",
    "    model.fit(X_train_balanced, y_train_balanced)\n",
    "    training_times[name] = time() - start_time\n",
    "\n",
    "    # Create a classification report after evaluating the test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    # Gather data for model comparisons\n",
    "    comparison_data.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': report['accuracy'],\n",
    "        'Macro F1': report['macro avg']['f1-score'],\n",
    "        'Training Time (s)': training_times[name],\n",
    "        'CV Mean Accuracy': cv_results[name]['mean'],\n",
    "        'CV Std': cv_results[name]['std']\n",
    "    })\n",
    "\n",
    "# Create a DataFrame for model comparison\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('Accuracy', ascending=False)\n",
    "\n",
    "# Print model comparison results\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Display the model's performance metrics\n",
    "metrics = ['Accuracy', 'Macro F1', 'CV Mean Accuracy']\n",
    "comparison_plot = comparison_df.melt(\n",
    "    id_vars=['Model'], \n",
    "    value_vars=metrics,\n",
    "    var_name='Metric',\n",
    "    value_name='Score'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=comparison_plot, x='Model', y='Score', hue='Metric')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Choose the model with the highest accuracy\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "# Print the best model and justification\n",
    "print(\"\\nBest Model Selection:\")\n",
    "print(f\"Selected Model: {best_model_name}\")\n",
    "print(\"\\nJustification:\")\n",
    "print(f\"1. Highest accuracy: {comparison_df.iloc[0]['Accuracy']:.4f}\")\n",
    "print(f\"2. Macro F1 Score: {comparison_df.iloc[0]['Macro F1']:.4f}\")\n",
    "print(f\"3. Cross-validation accuracy: {comparison_df.iloc[0]['CV Mean Accuracy']:.4f} (±{comparison_df.iloc[0]['CV Std']:.4f})\")\n",
    "print(f\"4. Training time: {comparison_df.iloc[0]['Training Time (s)']:.4f} seconds\")\n",
    "\n",
    "# Indicate feature relevance if Random Forest is the best model.\n",
    "if best_model_name == 'Random Forest' and hasattr(best_model, 'feature_importances_'):\n",
    "    feature_imp = pd.DataFrame({\n",
    "        'feature': dataset.columns,\n",
    "        'importance': best_model.feature_importances_\n",
    "    })\n",
    "    feature_imp = feature_imp.sort_values('importance', ascending=False).head(10)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=feature_imp, x='importance', y='feature')\n",
    "    plt.title('The Top 10 Most Important Features (Random Forest)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "##### This notebook demonstrated a methodical approach to human activity recognition by covering data exploration, preprocessing, model training, evaluation, and comparison. Following the evaluation of several models, the model with the greatest performance was Logistic Regression.\n",
    "\n",
    "### Best Model Selection:\n",
    "##### Logistic Regression\n",
    "\n",
    "- Highest accuracy: 0.9845\n",
    "- Macro F1 Score: 0.9854\n",
    "- Cross-validation accuracy: 0.9850 (±0.0022)\n",
    "- Training time: 1.4970 seconds\n",
    "\n",
    "##### The best accuracy and robust cross-validation results were obtained with Logistic Regression, which surpassed Random Forest and SVM in terms of both accuracy and efficiency. In this instance, the best model for activity classification tasks is logistic regression due to its ease of use and superior performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Libraries\n",
    "\n",
    "The analysis in this notebook utilizes several Python libraries:\n",
    "- **pandas**: Data manipulation and analysis.\n",
    "- **numpy**: Numerical operations.\n",
    "- **matplotlib** and **seaborn**: Data visualization.\n",
    "- **scikit-learn**: Machine learning tasks including preprocessing, dimensionality reduction (PCA), model training, and evaluation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
